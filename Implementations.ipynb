{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOba666wCmeduywxdfYgB3z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krishanu2206/Some_Implementations-/blob/main/Implementations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#THE LENET ARCHITECTURE\n",
        "The LeNet architecture is a simple and classic convolutional neural network (CNN) architecture, originally designed for handwritten digit recognition (MNIST dataset) by Yann LeCun. The architecture consists of two sets of convolutional and pooling layers, followed by fully connected layers.\n",
        "\n",
        "Convolutional Layer 1: Takes a 1-channel input (e.g., grayscale image) and outputs 6 feature maps with a kernel size of 5x5.\n",
        "\n",
        "Max Pooling Layer 1: Applies 2x2 max pooling.\n",
        "\n",
        "Convolutional Layer 2: Takes 6 input channels and outputs 16 feature maps with a kernel size of 5x5.\n",
        "\n",
        "Max Pooling Layer 2: Applies 2x2 max pooling.\n",
        "\n",
        "Flattening: Converts the 2D feature maps into a 1D feature vector.\n",
        "\n",
        "Fully Connected Layer 1: Outputs 120 features.\n",
        "\n",
        "Fully Connected Layer 2: Outputs 84 features.\n",
        "\n",
        "Output Layer: Outputs 10 features, corresponding to the number of classes.\n",
        "\n",
        "This architecture works well for small image classification tasks.\n",
        "\n",
        "`1x32x32 Input -> (5x5), s=1, p=0 -> (5x5), s=1, p=0 -> avg pool s=2, p=0 -> conv (5x5) to 120 channels x linear 120 -> 84 x Linear 10`"
      ],
      "metadata": {
        "id": "ffuCq-ISJDaC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lj24gLKI9FE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet, self).__init__()\n",
        "    self.relu = nn.ReLU()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.pool = nn.AvgPool2d(kernel_size=(2,2), stride=(2,2))\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(5,5), stride=(1,1), padding=(0,0))\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5,5), stride=(1,1), padding=(0,0))\n",
        "    self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=(5,5), stride=(1,1), padding=(0,0))\n",
        "    self.linear1 = nn.Linear(in_features=120, out_features=84)\n",
        "    self.linear2 = nn.Linear(in_features=84, out_features=10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu(self.conv1(x))\n",
        "    x = self.pool(x)\n",
        "    x = self.relu(self.conv2(x))\n",
        "    x = self.pool(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.relu(self.linear1(x))\n",
        "    x = self.linear2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "riTe3aKAfZx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(64, 1, 32, 32)"
      ],
      "metadata": {
        "id": "E2WtJeQMzZav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Creating an instance of the model\n",
        "model = LeNet()"
      ],
      "metadata": {
        "id": "wwu5LTGm0DDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model(x).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dyCqJ1C0KGH",
        "outputId": "74639296-39cc-4a47-b2db-9dc670292bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BaicL0560Pvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GOOGLENET/INCEPTIONNET ARCHITECTURE\n",
        "\n",
        "GoogleNet, also known as InceptionNet, is a deep convolutional neural network architecture introduced by Szegedy et al. in 2014. It won the ILSVRC 2014 challenge and is known for its Inception modules that capture multi-scale features.\n",
        "\n",
        "Key Features:\n",
        "Inception Module: Utilizes parallel convolutions of different kernel sizes (1x1, 3x3, 5x5) and max pooling to extract features at various scales. Outputs from these layers are concatenated, combining information efficiently.\n",
        "Dimensionality Reduction: Uses 1x1 convolutions to reduce the number of input channels before applying more computationally expensive convolutions, reducing the overall computation cost.\n",
        "Auxiliary Classifiers: Includes auxiliary classifiers at intermediate layers to combat the vanishing gradient problem and improve training efficiency.\n",
        "Deep Architecture: Contains 22 layers, stacking multiple Inception modules, making it significantly deeper than earlier networks like AlexNet and VGG.\n",
        "Benefits:\n",
        "Multi-Scale Feature Learning: Captures fine to coarse features in the same module.\n",
        "Efficient Computation: Reduces computational cost while maintaining high accuracy.\n",
        "State-of-the-Art Performance: Achieved high accuracy on large-scale image classification tasks.\n",
        "GoogleNetâ€™s innovative design influenced many subsequent deep learning architectures and remains an important milestone in the development of convolutional neural networks.\n",
        "\n",
        "For More - https://sahiltinky94.medium.com/know-about-googlenet-and-implementation-using-pytorch-92f827d675db\n",
        "\n",
        "https://arxiv.org/pdf/1409.4842v1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "32OnAJfZ6_yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "tN1fKlTL8ONM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class conv_block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, **kwargs):\n",
        "    super(conv_block, self).__init__()\n",
        "    self.relu = nn.ReLU()\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, **kwargs) # **kwargs = kernel size/stride/padding\n",
        "    self.batchnorm = nn.BatchNorm2d(num_features = out_channels)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.relu(self.batchnorm(self.conv(x)))\n"
      ],
      "metadata": {
        "id": "A-jbICWtBj9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Inception(nn.Module):\n",
        "  def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool): #red = reduction\n",
        "    super(Inception, self).__init__()\n",
        "\n",
        "    self.branch1 = conv_block(in_channels, out_1x1, kernel_size=1)\n",
        "\n",
        "    self.branch2 = nn.Sequential(\n",
        "        conv_block(in_channels, red_3x3, kernel_size=(1,1)),\n",
        "        conv_block(red_3x3, out_3x3, kernel_size=(3,3), padding=(1,1))\n",
        "    )\n",
        "\n",
        "    self.branch3 = nn.Sequential(\n",
        "        conv_block(in_channels, red_5x5, kernel_size=(1,1)),\n",
        "        conv_block(red_5x5, out_5x5, kernel_size=(5,5), padding=(2,2))\n",
        "    )\n",
        "\n",
        "    self.branch_pool = nn.Sequential(\n",
        "        nn.MaxPool2d(kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
        "        conv_block(in_channels, out_1x1pool, kernel_size=(1,1))\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    #N * filters * height * width\n",
        "    return torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch_pool(x)], 1) ##1 indicates the dimention along which the cnctenation needs to be done"
      ],
      "metadata": {
        "id": "IQ7feMFg1i68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogleNet(nn.Module):\n",
        "  def __init__(self, in_channels=3, num_classes=1000):\n",
        "    super(GoogleNet, self).__init__()\n",
        "\n",
        "    self.conv1 = conv_block(in_channels=3, out_channels=64, kernel_size=(7,7), stride=(2,2), padding=(3,3))\n",
        "    self.maxpool1 = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
        "\n",
        "    self.conv2 = conv_block(in_channels=64, out_channels=192, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "    self.maxpool2 = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
        "\n",
        "    self.inception3a = Inception(in_channels=192, out_1x1=64, red_3x3=96, out_3x3=128, red_5x5=16, out_5x5=32, out_1x1pool=32)\n",
        "    self.inception3b = Inception(in_channels=256, out_1x1=128, red_3x3=128, out_3x3=192, red_5x5=32, out_5x5=96, out_1x1pool=64)\n",
        "    self.maxpool3 = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
        "\n",
        "    self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)\n",
        "    self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)\n",
        "    self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
        "    self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)\n",
        "    self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
        "    self.maxpool4 = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
        "\n",
        "    self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
        "    self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
        "    self.avgpool = nn.AvgPool2d(kernel_size=(7,7), stride=(1,1))\n",
        "    self.dropout = nn.Dropout(p=0.4)\n",
        "    self.fc1 = nn.Linear(1024, 1000)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool2(x)\n",
        "    x = self.inception3a(x)\n",
        "    x = self.inception3b(x)\n",
        "    x = self.maxpool3(x)\n",
        "    x = self.inception4a(x)\n",
        "    x = self.inception4b(x)\n",
        "    x = self.inception4c(x)\n",
        "    x = self.inception4d(x)\n",
        "    x = self.inception4e(x)\n",
        "    x = self.maxpool4(x)\n",
        "    x = self.inception5a(x)\n",
        "    x = self.inception5b(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.reshape(x.shape[0], -1) #2024 x 1 x 1 -> (2024x1x1 = 2024)\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc1(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "a_mpYaLuEvis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.randn(3, 3, 224, 224)"
      ],
      "metadata": {
        "id": "gy5ss6dGHo-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create an instance of the class\n",
        "model = GoogleNet()"
      ],
      "metadata": {
        "id": "muODSKN3Hu11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = model(x).shape\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neqmL688HxAP",
        "outputId": "6f98d88e-aca3-423b-9852-9f0296ff1284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1000])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Es8rL2CAHzu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RESNET ARCHITECTURE\n",
        "\n",
        "For understanding RESNET and why to use RESNET -\n",
        "https://medium.com/@karuneshu21/resnet-paper-walkthrough-b7f3bdba55f0\n",
        "\n",
        "https://arxiv.org/pdf/1512.03385"
      ],
      "metadata": {
        "id": "NFiRD7rG7eUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "mx9b0_JA7hqh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "  \"\"\"\n",
        "        Creates a Bottleneck with conv 1x1->3x3->1x1 layers.\n",
        "\n",
        "        Note:\n",
        "          1. Addition of feature maps occur at just before the final ReLU with the input feature maps\n",
        "          2. if input size is different from output, select projected mapping or else identity mapping.\n",
        "          3. if is_Bottleneck=False (3x3->3x3) are used else (1x1->3x3->1x1). Bottleneck is required for resnet-50/101/152\n",
        "        Args:\n",
        "            in_channels (int) : input channels to the Bottleneck\n",
        "            intermediate_channels (int) : number of channels to 3x3 conv\n",
        "            expansion (int) : factor by which the input #channels are increased\n",
        "            stride (int) : stride applied in the 3x3 conv. 2 for first Bottleneck of the block and 1 for remaining\n",
        "\n",
        "        Attributes:\n",
        "            Layer consisting of conv->batchnorm->relu\n",
        "\n",
        "        \"\"\"\n",
        "  def __init__(self, in_channels, intermediate_channels, expansion, is_Bottleneck, stride=1):\n",
        "    super(Bottleneck, self).__init__()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.expansion = expansion\n",
        "    self.is_Bottleneck = is_Bottleneck\n",
        "    self.intermediate_channels = intermediate_channels\n",
        "    self.stride = stride\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    ##checking if the dimension of F(x) = dim(x)\n",
        "    if self.in_channels == self.expansion * self.intermediate_channels:\n",
        "      self.identity = True\n",
        "    else:\n",
        "      self.identity = False\n",
        "      projection_layer = []\n",
        "      projection_layer.append(nn.Conv2d(in_channels = self.in_channels, out_channels = self.expansion * self.intermediate_channels, kernel_size = 1, stride=stride, padding = 0, bias = False))\n",
        "      projection_layer.append(nn.BatchNorm2d(num_features = self.expansion * self.intermediate_channels))\n",
        "      self.projection = nn.Sequential(*projection_layer)\n",
        "\n",
        "    if self.is_Bottleneck:\n",
        "      self.convblock1_1x1 = nn.Conv2d(in_channels = self.in_channels, out_channels = self.intermediate_channels, kernel_size = 1, stride=1, padding = 0, bias = False)\n",
        "      self.batchnorm1 = nn.BatchNorm2d(num_features = self.intermediate_channels)\n",
        "\n",
        "      self.convblock2_3x3 = nn.Conv2d(in_channels = self.intermediate_channels, out_channels = self.intermediate_channels, kernel_size = 3, stride=self.stride, padding = 1, bias = False)\n",
        "      self.batchnorm2 = nn.BatchNorm2d(num_features = intermediate_channels)\n",
        "\n",
        "      self.convblock3_1x1 = nn.Conv2d(in_channels = self.intermediate_channels, out_channels = self.expansion * self.intermediate_channels, kernel_size = 1, stride=1, padding = 0, bias = False)\n",
        "      self.batchnorm3 = nn.BatchNorm2d(num_features = self.expansion * self.intermediate_channels)\n",
        "\n",
        "    else:\n",
        "      #basic block\n",
        "      self.convblock1_3x3 = nn.Conv2d(in_channels = self.in_channels, out_channels = self.intermediate_channels, kernel_size = 3, stride=self.stride, padding=1, bias = False)\n",
        "      self.batchnorm1 = nn.BatchNorm2d(num_features = intermediate_channels)\n",
        "\n",
        "      self.convblock2_3x3 = nn.Conv2d(in_channels = self.intermediate_channels, out_channels = self.intermediate_channels, kernel_size = 3, stride=1, padding=1, bias = False)\n",
        "      self.batchnorm2 = nn.BatchNorm2d(num_features = self.intermediate_channels)\n",
        "\n",
        "  def forward(self, x):\n",
        "    copy = x\n",
        "    if self.is_Bottleneck:\n",
        "      x = self.batchnorm3(self.convblock3_1x1(self.relu(self.batchnorm2(self.convblock2_3x3(self.relu(self.batchnorm1(self.convblock1_1x1(x))))))))\n",
        "    else:\n",
        "      x = self.batchnorm2(self.convblock2_3x3(self.relu(self.batchnorm1(self.convblock1_3x3(x)))))\n",
        "\n",
        "    if self.identity:\n",
        "      x = x + copy\n",
        "    else:\n",
        "      x = x + self.projection(copy)\n",
        "\n",
        "    return self.relu(x)\n"
      ],
      "metadata": {
        "id": "aDfWEvA8754n"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Now lets create the ResNet\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, input, in_channels, num_classes):\n",
        "    \"\"\"\n",
        "        Creates the ResNet architecture based on the provided variant. 18/34/50/101 etc.\n",
        "        Based on the input parameters, define the channels list, repeatition list along with expansion factor(4) and stride(3/1)\n",
        "        using _make_blocks method, create a sequence of multiple Bottlenecks\n",
        "        Average Pool at the end before the FC layer\n",
        "\n",
        "        Args:\n",
        "            resnet_variant (list) : eg. [[64,128,256,512],[3,4,6,3],4,True]\n",
        "            in_channels (int) : image channels (3)\n",
        "            num_classes (int) : output #classes\n",
        "\n",
        "        Attributes:\n",
        "            Layer consisting of conv->batchnorm->relu\n",
        "\n",
        "        \"\"\"\n",
        "    super(ResNet, self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.num_classes = num_classes\n",
        "    self.channels_list = input[0]\n",
        "    self.repeatition_list = input[1]\n",
        "    self.expansion = input[2]\n",
        "    self.is_Bottleneck = input[3]\n",
        "\n",
        "    self.convblock1 = nn.Conv2d(in_channels = self.in_channels, out_channels = 64, kernel_size =7, stride=2, padding=3, bias = False)\n",
        "    self.batchnorm1 = nn.BatchNorm2d(num_features = 64)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    self.convblock2 = self.make_blocks(in_channels = 64, intermediate_channels = self.channels_list[0], repeat = self.repeatition_list[0], expansion = self.expansion, is_Bottleneck = self.is_Bottleneck, stride = 1)\n",
        "    self.convblock3 = self.make_blocks(self.channels_list[0]*self.expansion, self.channels_list[1], self.repeatition_list[1], self.expansion, self.is_Bottleneck, stride=2)\n",
        "    self.convblock4 = self.make_blocks(self.channels_list[1]*self.expansion, self.channels_list[2], self.repeatition_list[2], self.expansion, self.is_Bottleneck, stride=2)\n",
        "    self.convblock5 = self.make_blocks(self.channels_list[2]*self.expansion, self.channels_list[3], self.repeatition_list[3], self.expansion, self.is_Bottleneck, stride=2)\n",
        "\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc = nn.Linear(self.channels_list[3]*self.expansion, self.num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu(self.batchnorm1(self.convblock1(x)))\n",
        "    x = self.maxpool(x)\n",
        "    x = self.convblock5(self.convblock4(self.convblock3(self.convblock2(x))))\n",
        "    x = self.flatten(self.avgpool(x))\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "  def make_blocks(self, in_channels, intermediate_channels, repeat, expansion, is_Bottleneck, stride):\n",
        "\n",
        "    layers = []\n",
        "    layers.append(Bottleneck(in_channels = in_channels, intermediate_channels = intermediate_channels, expansion = expansion, is_Bottleneck = is_Bottleneck, stride=stride))\n",
        "    for i in range(repeat-1):\n",
        "      layers.append(Bottleneck(in_channels = expansion * intermediate_channels, intermediate_channels = intermediate_channels, expansion = expansion, is_Bottleneck = is_Bottleneck, stride=1))\n",
        "\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dyQ8hwHTDGcQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = [[64,128,256,512],[3,4,6,3],4,True]\n",
        "model = ResNet( params, in_channels=3, num_classes=1000)\n",
        "x = torch.randn(1,3,224,224)\n",
        "output = model(x)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0BupWw2DNJq",
        "outputId": "4be5b519-1346-4028-a617-4cec47306883"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EFFICIENT NET ARCHITECTURE\n",
        "\n",
        "For more info - https://medium.com/@aniketthomas27/efficientnet-implementation-from-scratch-in-pytorch-a-step-by-step-guide-a7bb96f2bdaa"
      ],
      "metadata": {
        "id": "QTrjsxWBIC_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from math import ceil"
      ],
      "metadata": {
        "id": "aOIzABZqJy-e"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##initialising the required parameters\n",
        "basic_mb_params = [\n",
        "    # k, channels(c), repeats(t), stride(s), kernel_size(k)\n",
        "    [1, 16, 1, 1, 3],\n",
        "    [6, 24, 2, 2, 3],\n",
        "    [6, 40, 2, 2, 5],\n",
        "    [6, 80, 3, 2, 3],\n",
        "    [6, 112, 3, 1, 5],\n",
        "    [6, 192, 4, 2, 5],\n",
        "    [6, 320, 1, 1, 3],\n",
        "]\n",
        "\n",
        "alpha, beta = 1.2, 1.1\n",
        "\n",
        "scale_values = {\n",
        "    # (phi, resolution, dropout)\n",
        "    \"b0\": (0, 224, 0.2),\n",
        "    \"b1\": (0.5, 240, 0.2),\n",
        "    \"b2\": (1, 260, 0.3),\n",
        "    \"b3\": (2, 300, 0.3),\n",
        "    \"b4\": (3, 380, 0.4),\n",
        "    \"b5\": (4, 456, 0.4),\n",
        "    \"b6\": (5, 528, 0.5),\n",
        "    \"b7\": (6, 600, 0.5),\n",
        "}"
      ],
      "metadata": {
        "id": "H_PZI6jbIMl_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Conv Block\n",
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    super(ConvBlock, self).__init__()\n",
        "    self.convblock = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = kernel_size, stride = stride, padding = padding, groups = groups),\n",
        "        nn.BatchNorm2d(num_features = out_channels),\n",
        "        nn.SiLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.convblock(x)"
      ],
      "metadata": {
        "id": "WRBAQLbpIVyf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SqueezeExcitation\n",
        "class SqueezeExcitation(nn.Module):\n",
        "  def __init__(self, in_channels, reduced_channels):\n",
        "    super(SqueezeExcitation, self).__init__()\n",
        "    self.se = nn.Sequential(\n",
        "      nn.AdaptiveAvgPool2d(1),# C x H x W -> C x 1 x 1\n",
        "      nn.Conv2d(in_channels = in_channels, out_channels = reduced_channels, kernel_size = 1),\n",
        "      nn.SiLU(),\n",
        "      nn.Conv2d(in_channels = reduced_channels, out_channels = in_channels, kernel_size = 1),\n",
        "      nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return x * self.se(x)\n"
      ],
      "metadata": {
        "id": "iBrLApI8LNzl"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MBBlock\n",
        "class MBBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding, ratio, reduction=2):\n",
        "    super(MBBlock, self).__init__()\n",
        "    hidden_channels = in_channels * ratio\n",
        "    self.expand=0\n",
        "    if hidden_channels != in_channels:\n",
        "      self.expand = 1\n",
        "\n",
        "    reduced_channels = int(in_channels /reduction)\n",
        "\n",
        "    if self.expand == 1:\n",
        "      self.expand_conv = ConvBlock(in_channels = in_channels, out_channels = hidden_channels, kernel_size = 1, stride = 1, padding = 1)\n",
        "\n",
        "    self.conv = nn.Sequential(\n",
        "        ConvBlock(in_channels = hidden_channels, out_channels = hidden_channels, kernel_size = kernel_size, stride = stride, padding = padding, groups = hidden_channels),\n",
        "        SqueezeExcitation(hidden_channels, reduced_channels),\n",
        "        nn.Conv2d(in_channels = hidden_channels, out_channels = out_channels, kernel_size = 1),\n",
        "        nn.BatchNorm2d(num_features = out_channels)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.expand:\n",
        "      x = self.expand_conv(x)\n",
        "\n",
        "    return self.conv(x)"
      ],
      "metadata": {
        "id": "hlWfRouoJLRO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#EfficientNet\n",
        "class EfficientNet(nn.Module):\n",
        "  def __init__(self, model_name, output):\n",
        "    super(EfficientNet, self).__init__()\n",
        "    phi, resolution, dropout = scale_values[model_name]\n",
        "    self.depth_factor, self.width_factor = alpha ** phi, beta ** phi\n",
        "    self.num_classes = output\n",
        "    self.last_channels = ceil(1280 * self.width_factor)\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "    self.feature_extractor()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(self.last_channels, self.num_classes)\n",
        "    )\n",
        "\n",
        "  def feature_extractor(self):\n",
        "    channels = int(32 * self.width_factor)\n",
        "    features = [ConvBlock(in_channels = 3, out_channels = channels, kernel_size = 3, stride = 2, padding = 1)]\n",
        "    in_channels = channels\n",
        "\n",
        "    for k, c, repeat, s, n in basic_mb_params:\n",
        "      out_channels = 4*ceil(int(c*self.width_factor)/4)\n",
        "      depth = int(repeat * self.depth_factor)\n",
        "\n",
        "      for layer in range(depth):\n",
        "        if layer == 0:\n",
        "          stride = s\n",
        "        else:\n",
        "          stride =1\n",
        "        features.append(MBBlock(in_channels, out_channels, n, stride, n//2, k))\n",
        "        in_channels = out_channels\n",
        "\n",
        "    features.append(ConvBlock(in_channels = in_channels, out_channels = self.last_channels, kernel_size=1, stride=1, padding=0))\n",
        "\n",
        "    self.extractor = nn.Sequential(*features)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.classifier(self.flatten(self.avgpool(self.extractor(x))))\n"
      ],
      "metadata": {
        "id": "_abQcid6LL8g"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'b1'\n",
        "output = 1000 ##num_classes\n",
        "#creating an instance of the model\n",
        "model = EfficientNet(model_name, 1000)"
      ],
      "metadata": {
        "id": "mO0mGsota4fc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing\n",
        "x = torch.randn(1,3,224,224)\n",
        "output = model(x)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DSrYJPYbKYY",
        "outputId": "c897aeba-cbe8-4223-cb9b-76645612d96d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DOLNHLzGcmiT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}